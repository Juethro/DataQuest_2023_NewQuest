{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Juethro/DataQuest_2023_NewQuest/blob/kevin/DataQuest2023_revisi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Library"
      ],
      "metadata": {
        "id": "0pVsovUjflAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c tahap-penyisihan-oq-dataquestua"
      ],
      "metadata": {
        "id": "nznX6KlG1HVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip tahap-penyisihan-oq-dataquestua.zip -d datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoFRr_vUbZNZ",
        "outputId": "9f7a3bdd-6dbd-42bb-b0fc-96229bc7129f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  tahap-penyisihan-oq-dataquestua.zip\n",
            "replace datasets/sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace datasets/sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace datasets/sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JC8zbnaEbwtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft = pd.read_csv(\"datasets/train.csv\")\n",
        "dft"
      ],
      "metadata": {
        "id": "4ihCD4xeb0k_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Statistika Deskriptif"
      ],
      "metadata": {
        "id": "Mr3kljWzfuj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dft.info()"
      ],
      "metadata": {
        "id": "zLSkem2xb_HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dft)"
      ],
      "metadata": {
        "id": "vSa3mMf8fxTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft.describe().transpose()"
      ],
      "metadata": {
        "id": "3VYivsODf75U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Prepocessing"
      ],
      "metadata": {
        "id": "gzMP7o0fglN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dft.drop(\"time-zone\", axis=1, inplace=True)\n",
        "dft['temp'] = dft['temp'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft['d_point'] = dft['d_point'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft['feels'] = dft['feels'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft['min_temp'] = dft['min_temp'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft['max_temp'] = dft['max_temp'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft['prssr'] = dft['prssr'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft['hum'] = dft['hum'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft['wind_spd'] = dft['wind_spd'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft['wind_deg'] = dft['wind_deg'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft[\"clouds\"] = dft[\"clouds\"].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "\n",
        "dft[\"rain_1h\"] = dft['rain_1h'].str.replace('zero', '0')\n",
        "dft['rain_1h'] = dft['rain_1h'].replace('-1m', '-1')\n",
        "dft[\"rain_1h\"] = dft['rain_1h'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "\n",
        "dft[\"rain_3h\"] = 0\n",
        "dft[\"snow_1h\"] = 0\n",
        "dft[\"snow_3h\"] = 0"
      ],
      "metadata": {
        "id": "L58T97IagnX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft.info()"
      ],
      "metadata": {
        "id": "ZLmQGBgphG0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft.head(20)"
      ],
      "metadata": {
        "id": "KI-S26eThLow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft.info()"
      ],
      "metadata": {
        "id": "paY2UN1ewFyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft.isna().sum()"
      ],
      "metadata": {
        "id": "NgVlmNqSh7UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft.rain_1h"
      ],
      "metadata": {
        "id": "B_ntH4V3QwdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft['rain_1h'].fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "bXWd2rG6RQq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Menghapus Variabel"
      ],
      "metadata": {
        "id": "fCVg2QWGjYNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['datetime', 'visibility', 'sea_level', 'grnd_level']\n",
        "\n",
        "dft = dft.drop(columns_to_drop, axis =1)\n",
        "\n",
        "# # Menghapus dan mengambil kolom-kolom tersebut\n",
        "# for column in columns_to_drop:\n",
        "#     removed_column = dft.pop(column)"
      ],
      "metadata": {
        "id": "E-m7jUqMjX3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft.info()"
      ],
      "metadata": {
        "id": "WoJcFAUTjwlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft.head()"
      ],
      "metadata": {
        "id": "0we4D4tyT6OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mendeteksi Outlier"
      ],
      "metadata": {
        "id": "NhY2NBSr-SE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "columns_to_check = ['temp', 'd_point', 'feels', 'min_temp', 'max_temp', 'prssr', 'hum', 'wind_spd', 'wind_deg', 'rain_1h', 'rain_3h', 'snow_1h', 'snow_3h', 'clouds']\n",
        "\n",
        "# Hitung Z-score untuk setiap kolom\n",
        "z_scores = stats.zscore(dft[columns_to_check])\n",
        "\n",
        "# Tentukan ambang batas Z-score untuk deteksi outlier (misalnya, 2 atau 3)\n",
        "threshold = 3\n",
        "\n",
        "# Deteksi outlier\n",
        "outliers = (z_scores > threshold).any(axis=1)\n",
        "\n",
        "# Tampilkan baris-baris yang berisi outlier\n",
        "dft[outliers]"
      ],
      "metadata": {
        "id": "JQmexUEc-UdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Tentukan kolom yang akan dianalisis (kolom numerik)\n",
        "columns_to_check = ['temp', 'd_point', 'feels', 'min_temp', 'max_temp', 'prssr', 'hum', 'wind_spd', 'wind_deg', 'rain_1h', 'rain_3h', 'snow_1h', 'snow_3h', 'clouds']\n",
        "\n",
        "# Hitung Z-score untuk setiap kolom\n",
        "z_scores = stats.zscore(dft[columns_to_check])\n",
        "\n",
        "# Tentukan ambang batas Z-score untuk deteksi outlier (misalnya, 2 atau 3)\n",
        "threshold = 3\n",
        "\n",
        "# Deteksi outlier\n",
        "outliers = (z_scores > threshold).any(axis=1)\n",
        "\n",
        "# Gantikan outlier dengan nilai rata-rata\n",
        "for column in columns_to_check:\n",
        "    mean_value = dft[column].mean()\n",
        "    dft.loc[outliers, column] = mean_value\n",
        "\n",
        "# Tampilkan DataFrame yang telah menggantikan outlier dengan nilai rata-rata\n",
        "dft"
      ],
      "metadata": {
        "id": "vEX9Sqzg_fdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grafik"
      ],
      "metadata": {
        "id": "zoTSLWzHksdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dft.hist(bins=15, figsize=(12,10), alpha=0.6, label=False)"
      ],
      "metadata": {
        "id": "eOVlyExTkutu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft.isna().sum()"
      ],
      "metadata": {
        "id": "rNQExUVWk2uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelling"
      ],
      "metadata": {
        "id": "rAc9digKSqQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Regresi Linier"
      ],
      "metadata": {
        "id": "Cn0X8OSdzIF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Memisahkan variabel independen (fitur) dan variabel dependen (target)\n",
        "X = dft[['temp','d_point', 'feels', 'min_temp', 'max_temp', 'prssr', 'hum', 'wind_spd', 'wind_deg', 'rain_3h', 'snow_1h', 'snow_3h', 'clouds']]\n",
        "y = dft['rain_1h']\n",
        "\n",
        "# Membagi data menjadi data latih dan data uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Inisialisasi model regresi linier\n",
        "model_lr = LinearRegression()\n",
        "\n",
        "# Melatih model pada data latih\n",
        "model_lr.fit(X_train, y_train)\n",
        "\n",
        "# Memprediksi data uji\n",
        "y_pred = model_lr.predict(X_test)\n",
        "\n",
        "# Menghitung metrik evaluasi (misalnya, MSE dan R-squared)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Menghitung RMSE\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "print(\"R-squared:\", r2)\n"
      ],
      "metadata": {
        "id": "0kc8lUMlSp5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Neural Networks"
      ],
      "metadata": {
        "id": "9zSYHeS30IIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Memisahkan variabel independen (fitur) dan variabel dependen (target)\n",
        "X = dft[['temp', 'd_point', 'feels', 'min_temp', 'max_temp', 'prssr', 'hum', 'wind_spd', 'wind_deg', 'rain_3h', 'snow_1h', 'snow_3h', 'clouds']]\n",
        "y = dft['rain_1h']\n",
        "\n",
        "# Membagi data menjadi data latih dan data uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Inisialisasi model jaringan saraf tiruan\n",
        "model_nn = Sequential()\n",
        "model_nn.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model_nn.add(Dense(64, activation='relu'))\n",
        "model_nn.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Kompilasi model\n",
        "model_nn.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Melatih model pada data latih\n",
        "model_nn.fit(X_train, y_train, epochs=100, batch_size=32)\n",
        "\n",
        "# Memprediksi data uji\n",
        "y_pred = model_nn.predict(X_test)\n",
        "\n",
        "# Menghitung metrik evaluasi (misalnya, MSE dan R-squared)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Menghitung RMSE\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "print(\"R-squared:\", r2)\n"
      ],
      "metadata": {
        "id": "EplR47ar0H19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XGB"
      ],
      "metadata": {
        "id": "iRc19qilKZTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dft['datetime_iso'] = pd.to_datetime(dft['datetime_iso'])\n",
        "\n",
        "# Ekstrak fitur-fitur dari kolom datetime_iso\n",
        "dft['year'] = dft['datetime_iso'].dt.year\n",
        "dft['month'] = dft['datetime_iso'].dt.month\n",
        "dft['day'] = dft['datetime_iso'].dt.day\n",
        "dft['hour'] = dft['datetime_iso'].dt.hour"
      ],
      "metadata": {
        "id": "Ps00qVF9LBoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft['visibility'] = pd.to_numeric(dft['visibility'], errors='coerce')  # Mengkonversi ke float\n",
        "dft['visibility'].fillna(0, inplace=True)  # Mengganti nilai yang hilang dengan 0"
      ],
      "metadata": {
        "id": "KA3od3TSLlLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft['sea_level'] = pd.to_numeric(dft['sea_level'], errors='coerce')"
      ],
      "metadata": {
        "id": "_j6iiFAvLyKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Memisahkan fitur (features) dan target (target)\n",
        "X = dft.drop(columns=['temp', 'd_point', 'feels', 'min_temp', 'max_temp', 'prssr', 'hum', 'wind_spd', 'wind_deg', 'rain_3h', 'snow_1h', 'snow_3h', 'clouds'])  # Ganti 'target' dengan nama kolom target yang sesuai\n",
        "y = dft['rain_1h']\n",
        "\n",
        "# Memisahkan data menjadi data latih dan data uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Membuat model XGBoost\n",
        "model_xgb = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Melatih model pada data latih\n",
        "model_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Membuat prediksi pada data uji\n",
        "y_pred = model_xgb.predict(X_test)\n",
        "\n",
        "# Menghitung mean squared error (MSE) sebagai metrik evaluasi\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Menghitung Root Mean Squared Error (RMSE)\n",
        "rmse = mse ** 0.5\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
      ],
      "metadata": {
        "id": "x84EGUpkKeRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Coba-coba"
      ],
      "metadata": {
        "id": "1KO7tbrBMpl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Library for modelling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Pisahkan fitur (variabel independen) dan target (rain_1h) dari dataset\n",
        "X = dft.drop(columns=['rain_1h', 'datetime_iso'])\n",
        "y = dft['rain_1h']"
      ],
      "metadata": {
        "id": "yOXb358aMrCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bagi data menjadi data pelatihan (train set) dan data pengujian (test set)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "h8G_pwmLMsSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = ['temp', 'd_point', 'feels']  # Ganti dengan kolom-kolom yang sesuai\n",
        "dft[categorical_cols] = dft[categorical_cols].astype('category')\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)"
      ],
      "metadata": {
        "id": "C9shLponNL0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Buat dan latih model XGBoost\n",
        "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Membuat prediksi pada data uji\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Menghitung Root Mean Squared Error (RMSE)\n",
        "rmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)\n",
        "print(f'XGBoost- RMSE: {rmse_xgb}')"
      ],
      "metadata": {
        "id": "ELJ0X7FWM1vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Kolom-kolom kategorikal yang ingin diubah\n",
        "categorical_cols = ['temp', 'd_point', 'feels']  # Ganti dengan kolom-kolom yang sesuai\n",
        "\n",
        "# Melakukan label encoding untuk setiap kolom kategorikal\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    label_encoder = LabelEncoder()\n",
        "    dft[col] = label_encoder.fit_transform(dft[col])\n",
        "    label_encoders[col] = label_encoder\n",
        "\n",
        "# Memisahkan fitur (features) dan target (target)\n",
        "X = dft.drop(columns=['rain_1h', 'datetime_iso'])\n",
        "y = dft['rain_1h']\n",
        "\n",
        "# Melakukan pemisahan data menjadi data latih dan data uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Membuat dan melatih model XGBoost\n",
        "xgb_models = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "xgb_models.fit(X_train, y_train)\n",
        "\n",
        "# Membuat prediksi pada data uji\n",
        "y_pred_xgb = xgb_models.predict(X_test)\n",
        "\n",
        "# Menghitung Root Mean Squared Error (RMSE)\n",
        "rmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)\n",
        "print(f'XGBoost- RMSE: {rmse_xgb}')"
      ],
      "metadata": {
        "id": "cLw00JbmNzIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uploader"
      ],
      "metadata": {
        "id": "7cSHJovY0mii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dft_test = pd.read_csv('datasets/test.csv')"
      ],
      "metadata": {
        "id": "AgnDe5p80saf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft_test"
      ],
      "metadata": {
        "id": "V04rsTk98Dzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft_test['temp'] = dft_test['temp'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft_test['d_point'] = dft_test['d_point'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft_test['feels'] = dft_test['feels'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft_test['min_temp'] = dft_test['min_temp'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft_test['max_temp'] = dft_test['max_temp'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft_test['prssr'] = dft_test['prssr'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft_test['hum'] = dft_test['hum'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft_test['wind_spd'] = dft_test['wind_spd'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft_test['wind_deg'] = dft_test['wind_deg'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "dft_test[\"clouds\"] = dft_test[\"clouds\"].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "\n",
        "dft_test[\"rain_3h\"] = 0\n",
        "dft_test[\"snow_1h\"] = 0\n",
        "dft_test[\"snow_3h\"] = 0"
      ],
      "metadata": {
        "id": "IT0-kJdt8Hc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft_test"
      ],
      "metadata": {
        "id": "pX6vm_ub8bhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft_test.isna().sum()"
      ],
      "metadata": {
        "id": "rnSwZQtzKMH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft_test.drop(columns=columns_to_drop, inplace=True)"
      ],
      "metadata": {
        "id": "XMA9mCiU7swK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft_test.isna().sum()"
      ],
      "metadata": {
        "id": "KZd6r4FB8vNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_train_dft = dft['d_point'].mean()\n",
        "dft_test['d_point'].fillna(mean_train_dft, inplace=True)"
      ],
      "metadata": {
        "id": "WIhMFm2d8ymH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#columns_to_drop = ['time-zone']\n",
        "#dft_test.drop(columns=columns_to_drop, inplace=True)"
      ],
      "metadata": {
        "id": "MP_ordV192ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft_test"
      ],
      "metadata": {
        "id": "jvl0ZNrP-L0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = dft_test[['datetime_iso']]\n",
        "dft_test = dft_test.drop(['time-zone', 'datetime_iso'], axis=1)"
      ],
      "metadata": {
        "id": "nGu_NYBlE5Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "Amxa3WfDGbNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_new = model_lr.predict(dft_test)\n",
        "result['rain_1h'] = y_pred_new"
      ],
      "metadata": {
        "id": "ytdsDa1c-TK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "OpgvB3u9GAMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.to_csv('submission linier.csv', index=False)"
      ],
      "metadata": {
        "id": "T88jocUzExm3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}